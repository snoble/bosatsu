# Runtime JIT for Map-Based UI Bindings

**Date**: 2026-01-31
**Status**: Experimental proposal
**Tags**: performance, v8-optimization, web-workers, jit

## What We're Building

A background JIT compiler that observes hot paths through BosatsuUI's Map-based binding system and generates specialized JavaScript code, eliminating the "interpreter overhead" of Map traversal.

### The Core Insight

BosatsuUI's Map structure (`Map<Id, Bindings>`, `Map<Id, Map<Key, Bindings>>`) **is a program encoded as data**. When the main thread traverses these Maps to find what DOM to update, V8 sees data access, not executable code. V8's JIT can't optimize this "interpretation" - it will never inline the Map lookups or specialize the binding application.

**Analogy**:
- Interpreting TypedExpr with ScalaJS → slow
- JsGen-compiled code → fast
- Map-based binding traversal → V8 sees data access
- Generated `getElementById().textContent = state.x` → V8 can inline

### Why Web Workers

Workers provide **true threading** (not event loop), so code generation can run continuously without blocking UI updates. The Worker acts as a background JIT compiler, always analyzing stats and generating the next optimization.

## Why This Approach

### The Problem

Current flow for updating a comment's likes:

```javascript
function updateLikes(commentId, newLikes) {
  // 1. Map lookup (V8 can't inline)
  const bindings = commentBindings.get(commentId);

  // 2. Linear search or another Map lookup
  const likesBinding = bindings.find(b => b.field === 'likes');

  // 3. Cached element lookup
  const element = elementCache.get(likesBinding.elementId);

  // 4. Finally, the actual DOM update
  element.textContent = String(newLikes);
}
```

V8 sees: `data → data → data → DOM`. It can't prove the Maps don't change between calls, so it can't specialize.

### The Solution

Generate direct code for hot paths:

```javascript
// Generated by Worker for hot path 'c1.likes'
export function updateC1Likes(newLikes) {
  document.getElementById('c1-likes').textContent = String(newLikes);
}
```

V8 sees: `DOM call → property write`. This can be fully inlined and optimized.

### Why Not Static Generation?

Static generation works when the binding structure is known at compile time. But some BosatsuUI apps have:
- User-generated content (comments, posts) creating bindings dynamically
- Database-driven UI where the "program" comes from data
- Long-running apps where usage patterns emerge over time

These need **runtime** optimization.

## Key Decisions

### 1. Integration Mechanism: Blob URL Modules

**Decision**: Use `URL.createObjectURL(new Blob([code]))` + dynamic `import()`

**Rationale**:
- CSP-safe (unlike `eval`/`new Function`)
- V8 treats imported modules as first-class (full JIT)
- Cacheable - module URL persists until revoked
- Clean hot-swap via new import

**Not chosen**:
- Wasm: Can't touch DOM directly, adds toolchain complexity
- `new Function()`: Blocked by CSP in many environments
- SharedArrayBuffer: Solves wrong problem (state sync, not binding lookup)

### 2. Generation Granularity: State Slice (Entity-Oriented)

**Decision**: Generate one module per "entity" (Comment, CartItem, etc.)

```javascript
// generated-comment-c1-runtime.js
const elements = {
  author: document.getElementById('c1-author'),
  content: document.getElementById('c1-content'),
  likes: document.getElementById('c1-likes')
};

export function updateC1(state) {
  if (state.author !== undefined) elements.author.textContent = state.author;
  if (state.content !== undefined) elements.content.textContent = state.content;
  if (state.likes !== undefined) elements.likes.textContent = String(state.likes);
}
```

**Rationale**:
- Matches type structure (each entity type has known fields)
- Single function call for coherent updates
- Simpler to generate than fine-grained binding functions
- V8 sees consistent call signature

**Evolution path**: If benchmarks show specific fields are much hotter, split to adaptive (cluster hot fields).

### 3. Worker Architecture: Continuous Background Compilation

**Decision**: Worker runs continuously, always looking for next best optimization candidate

**Rationale**:
- No explicit trigger threshold needed
- Naturally prioritizes hottest paths
- True parallelism means no main thread blocking
- Mimics how V8's TurboFan and HotSpot work

**Stats flow**:
```
Main Thread                          Worker
     │                                  │
     │── postMessage(stats) ──────────▶│
     │                                  │ analyze, find hot paths
     │                                  │ generate code
     │◀── postMessage(blobUrl) ────────│
     │                                  │
import(blobUrl)                         │
hot-swap handler                        │
```

### 4. Benchmark-Driven Adoption

**Decision**: This is experimental. Only adopt if benchmarks show measurable improvement.

**Metrics to track**:
- Time per binding update (Map traversal vs generated)
- Updates per second at various scales (10, 100, 1000 bindings)
- Memory overhead of generated modules
- Time to first optimization (Worker startup + generation)

**Acceptance criteria** (tentative):
- 2x+ speedup for hot paths at 100+ bindings
- No regression for cold paths
- Memory overhead < 10% of base

## Open Questions

1. **Invalidation**: When a binding changes (element removed, path restructured), how do we invalidate generated code?
   - Option A: Re-generate entire entity module
   - Option B: Track generation version, check before use
   - Option C: Let stale code fail gracefully, fall back to interpreted

2. **Stats collection overhead**: How much does tracking access patterns cost?
   - Option A: Sample (track every Nth access)
   - Option B: Batch counters, send periodically
   - Option C: Let Worker query state on demand

3. **Module lifecycle**: When to revoke Blob URLs? Memory accumulates if we never clean up.
   - Option A: Revoke old URL when new version generated
   - Option B: LRU cache of N most recent modules
   - Option C: Revoke all on navigation/SPA route change

4. **Cold start**: First-time visitors won't have optimization. Is Map traversal fast enough as baseline?
   - Current batching already provides 20x improvement
   - This optimization is additive, not required for correctness

## Architecture Sketch

```
┌─────────────────────────────────────────────────────────────┐
│ Main Thread                                                 │
│                                                             │
│  ┌──────────────┐    ┌─────────────────────────────────┐   │
│  │ BosatsuUI    │    │ OptimizationIntegration         │   │
│  │ Runtime      │───▶│ - statsCollector                │   │
│  │              │    │ - optimizedHandlers: Map        │   │
│  │ setState()   │    │ - fallbackToInterpreted()       │   │
│  └──────────────┘    └─────────────────────────────────┘   │
│         │                        │                          │
│         │ stats                  │ import(blobUrl)          │
│         ▼                        ▼                          │
└─────────┼────────────────────────┼──────────────────────────┘
          │                        │
    postMessage              postMessage
          │                        │
          ▼                        │
┌─────────────────────────────────────────────────────────────┐
│ Worker Thread                                               │
│                                                             │
│  ┌──────────────────────────────────────────────────────┐  │
│  │ JITCompiler                                          │  │
│  │                                                      │  │
│  │ while (true):                                        │  │
│  │   stats = receive()                                  │  │
│  │   candidate = findHottestUnoptimized(stats)          │  │
│  │   code = generateStateSliceRuntime(candidate)        │  │
│  │   blobUrl = createBlobUrl(code)                      │  │
│  │   send(blobUrl)                                      │  │
│  └──────────────────────────────────────────────────────┘  │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

## Next Steps

1. **Create experimental branch**: `experimental/runtime-jit`
2. **Build benchmark harness**: Measure Map traversal vs direct code at various scales
3. **Implement stats collector**: Track binding access frequency
4. **Implement Worker JIT**: Start with simple state-slice generation
5. **Measure**: Compare baseline vs optimized at 10, 100, 1000 bindings
6. **Decide**: If 2x+ improvement at scale, continue development

## References

- V8 JIT optimization: https://v8.dev/blog/turbofan-jit
- Web Workers: https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API
- Blob URLs: https://developer.mozilla.org/en-US/docs/Web/API/URL/createObjectURL
- Profile-guided optimization: https://en.wikipedia.org/wiki/Profile-guided_optimization
